import streamlit as st
import os
from utils import document_parser, text_cleaner, summarizer, embedder, search_faiss, classifier, mailer
from langchain.globals import set_verbose
import pickle

# LangChain verbose ì„¤ì •
set_verbose(True)

st.set_page_config(page_title="ìƒë‹´ ê¸°ë¡ ë¶„ì„", layout="wide")

st.title("ğŸ“ ìƒë‹´ ê¸°ë¡ ë¶„ì„ ë°ëª¨")

# -----------------------
# 1. PDF ì—…ë¡œë“œ
# -----------------------
uploaded_file = st.file_uploader("ğŸ“„ ìƒë‹´ ê¸°ë¡ PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    st.success("âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ!")

    # ì§„í–‰ ìƒíƒœ í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ
    progress_container = st.empty()
    status_container = st.empty()

    try:
        # 2. ë¬¸ì„œ íŒŒì‹±
        with st.spinner("ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
            status_container.info("ğŸ“„ PDF íŒŒì¼ íŒŒì‹± ì¤‘...")
            raw_text = document_parser.parse(uploaded_file)
            progress_container.progress(20, "ë¬¸ì„œ íŒŒì‹± ì™„ë£Œ")
        
        # 3. í…ìŠ¤íŠ¸ ì •ì œ ë° ìµëª…í™”
        status_container.info("ğŸ§¹ í…ìŠ¤íŠ¸ ì •ì œ ë° ìµëª…í™” ì¤‘...")
        # ì²­í¬ ìˆ˜ì— ë”°ë¼ ì§„í–‰ë¥  ê³„ì‚°
        chunks = text_cleaner.chunk_text(raw_text)
        total_chunks = len(chunks)
        
        def update_progress(chunk_num):
            base_progress = 20  # ì´ì „ ë‹¨ê³„ì˜ ì§„í–‰ë¥ 
            chunk_progress = (chunk_num / total_chunks) * 20  # ì²­í¬ ì²˜ë¦¬ ì§„í–‰ë¥ 
            total_progress = base_progress + chunk_progress
            progress_container.progress(int(total_progress), f"í…ìŠ¤íŠ¸ ì •ì œ ì¤‘... ({chunk_num}/{total_chunks})")
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜ë¥¼ ì „ë‹¬
        clean_text = text_cleaner.clean(raw_text, progress_callback=update_progress)
        progress_container.progress(40, "í…ìŠ¤íŠ¸ ì •ì œ ì™„ë£Œ")

        # 4. ìš”ì•½ 
        status_container.info("ğŸ“ ìƒë‹´ ë‚´ìš© ìš”ì•½ ì¤‘...")
        summary = summarizer.summarize(clean_text)
        progress_container.progress(60, "ìš”ì•½ ì™„ë£Œ")

        # 5. ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
        print("ğŸ” ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ì¤‘...")
        all_results = []
        for chunk in chunks:
            # í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì „ë‹¬
            chunk_results = search_faiss.search(chunk)
            all_results.extend(chunk_results)
        
        # ê²°ê³¼ë¥¼ ì ìˆ˜ë³„ë¡œ ì •ë ¬í•˜ê³  ì¤‘ë³µ ì œê±°
        seen_docs = set()  # (file_path, text) íŠœí”Œì„ ì €ì¥
        similar_cases = []
        for result in sorted(all_results, key=lambda x: x['score'], reverse=True):
            # íŒŒì¼ ê²½ë¡œì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ì²´í¬
            doc_key = (result['file_path'], result['text'])
            if doc_key not in seen_docs:
                seen_docs.add(doc_key)
                similar_cases.append(result)
                if len(similar_cases) >= 3:  # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ìœ ì§€
                    break
        
        progress_container.progress(80, "ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ì™„ë£Œ")

        # 6. ë¶„ë¥˜
        status_container.info("ğŸ·ï¸ ìƒë‹´ ë¶„ë¥˜ ì¤‘...")
        classification = classifier.classify(summary, similar_cases)
        progress_container.progress(100, "ë¶„ë¥˜ ì™„ë£Œ")
        
        # ì§„í–‰ ìƒíƒœ ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™”
        progress_container.empty()
        status_container.empty()

        # -----------------------
        # streamlit UI
        # -----------------------

        # ì›ë³¸ í…ìŠ¤íŠ¸ (ì ‘ì„ ìˆ˜ ìˆëŠ” ì„¹ì…˜)
        with st.expander("ğŸ“„ ì›ë³¸ í…ìŠ¤íŠ¸ ë³´ê¸°"):
            st.text_area("ì •ì œëœ í…ìŠ¤íŠ¸", clean_text, height=200)

        # êµ¬ì¡°í™”ëœ ìš”ì•½ ê²°ê³¼
        st.subheader("ğŸ§  ìƒë‹´ ìš”ì•½ ê²°ê³¼")
        st.write(summary)  # ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ í‘œì‹œ

        # ìœ ì‚¬ì‚¬ë¡€ ìš”ì•½ ì¹´ë“œ
        st.subheader("ğŸ” ìœ ì‚¬ ì‚¬ë¡€")
        for i, case in enumerate(similar_cases):
            with st.expander(f"ìœ ì‚¬ ì‚¬ë¡€ {i+1} (ìœ ì‚¬ë„: {case['score']:.2f})"):
                st.markdown(
                    f"""
                    <div style="border:1px solid #ddd; border-radius:12px; padding:16px; margin:8px;">
                        <p><b>ì œëª©:</b> {case['text']}</p>
                        <p><b>ìƒì„¸ ë‚´ìš©:</b> {case['details']}</p>
                        <p><b>ë‚ ì§œ:</b> {case['date']}</p>
                    </div>
                    """, unsafe_allow_html=True
                )
                
                # ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                if case['file_path'] and os.path.exists(case['file_path']):
                    with open(case['file_path'], 'rb') as f:
                        file_data = f.read()
                        st.download_button(
                            label="ğŸ“¥ ì›ë³¸ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ",
                            data=file_data,
                            file_name=os.path.basename(case['file_path']),
                            mime="application/pdf"
                        )

        # -----------------------
        # 7. ìœ„í—˜ ì•Œë¦¼
        if classification.get("emergency_level", 0) >= 3 or classification.get("abuse_type", "í•´ë‹¹ì—†ìŒ") != "í•´ë‹¹ì—†ìŒ":
            with st.spinner("ğŸš¨ ìœ„í—˜ ì•Œë¦¼ ë°œì†¡ ì¤‘..."):
                mailer.send_alert({
                    "type": classification.get("problem_type", ""),
                    "risk_level": classification.get("emergency_level", 0),
                    "abuse_type": classification.get("abuse_type", "í•´ë‹¹ì—†ìŒ"),
                    "timestamp": classification.get("timestamp", "")
                })
                st.warning("ğŸš¨ ìœ„í—˜ ìƒë‹´ ê°ì§€ë¨! ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼ ë°œì†¡ë¨")

        # 8. ë¡œê·¸
        st.subheader("ğŸ•’ ì•Œë¦¼ ë¡œê·¸")
        st.code(f"ë©”ì¼ ë°œì†¡ ì™„ë£Œ: {classification.get('timestamp', '')}")

    except FileNotFoundError as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.info("ğŸ’¡ í•´ê²° ë°©ë²•: faiss_index ë””ë ‰í† ë¦¬ì— í•„ìš”í•œ íŒŒì¼ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")